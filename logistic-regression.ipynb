{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Credit Card Fraud"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will be detecting credit card fraud based on the different features of our dataset with 3 different models. Here is the Logistic Regression one.\n",
    "\n",
    "We're looking to minimize the False Negative Rate or FNR.\n",
    "\n",
    "Since the dataset is unbalanced, we can try two techniques that may help us have better predictions:\n",
    "\n",
    "    - Adding some noise (gaussian) to the fraud data to create more and reduce the imbalance\n",
    "    - Randomly sample the fraud data and train k models and average them out (or choose the best)\n",
    "    \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sklearn as sk\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import scale\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>131418.0</td>\n",
       "      <td>-1.418343</td>\n",
       "      <td>2.074760</td>\n",
       "      <td>-1.683303</td>\n",
       "      <td>-1.708984</td>\n",
       "      <td>1.340667</td>\n",
       "      <td>-0.802904</td>\n",
       "      <td>1.571283</td>\n",
       "      <td>-0.183383</td>\n",
       "      <td>0.610996</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.016737</td>\n",
       "      <td>0.831867</td>\n",
       "      <td>-0.287168</td>\n",
       "      <td>0.217734</td>\n",
       "      <td>-0.062399</td>\n",
       "      <td>-0.017927</td>\n",
       "      <td>0.005060</td>\n",
       "      <td>-0.455670</td>\n",
       "      <td>3.70</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>30575.0</td>\n",
       "      <td>-2.007359</td>\n",
       "      <td>-1.812544</td>\n",
       "      <td>2.467946</td>\n",
       "      <td>0.717333</td>\n",
       "      <td>0.860664</td>\n",
       "      <td>-0.474420</td>\n",
       "      <td>-1.195674</td>\n",
       "      <td>0.418655</td>\n",
       "      <td>-1.559050</td>\n",
       "      <td>...</td>\n",
       "      <td>0.122850</td>\n",
       "      <td>0.295340</td>\n",
       "      <td>0.275766</td>\n",
       "      <td>0.213621</td>\n",
       "      <td>0.368420</td>\n",
       "      <td>-0.093973</td>\n",
       "      <td>0.056136</td>\n",
       "      <td>0.122159</td>\n",
       "      <td>97.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>48759.0</td>\n",
       "      <td>-1.455090</td>\n",
       "      <td>1.745371</td>\n",
       "      <td>0.393814</td>\n",
       "      <td>0.370542</td>\n",
       "      <td>0.419204</td>\n",
       "      <td>0.547102</td>\n",
       "      <td>-0.058742</td>\n",
       "      <td>-0.476353</td>\n",
       "      <td>-0.677755</td>\n",
       "      <td>...</td>\n",
       "      <td>0.920543</td>\n",
       "      <td>-0.148314</td>\n",
       "      <td>-0.188817</td>\n",
       "      <td>-1.033784</td>\n",
       "      <td>-0.091466</td>\n",
       "      <td>-0.409897</td>\n",
       "      <td>-0.612491</td>\n",
       "      <td>0.083665</td>\n",
       "      <td>5.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>66544.0</td>\n",
       "      <td>1.124034</td>\n",
       "      <td>-0.343542</td>\n",
       "      <td>1.361168</td>\n",
       "      <td>0.387759</td>\n",
       "      <td>-1.390420</td>\n",
       "      <td>-0.663302</td>\n",
       "      <td>-0.530391</td>\n",
       "      <td>-0.051080</td>\n",
       "      <td>0.999240</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.170236</td>\n",
       "      <td>-0.236974</td>\n",
       "      <td>0.109470</td>\n",
       "      <td>1.023537</td>\n",
       "      <td>0.092587</td>\n",
       "      <td>0.903247</td>\n",
       "      <td>-0.030670</td>\n",
       "      <td>0.026613</td>\n",
       "      <td>34.66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>121099.0</td>\n",
       "      <td>0.072966</td>\n",
       "      <td>1.004738</td>\n",
       "      <td>-0.452590</td>\n",
       "      <td>-0.530909</td>\n",
       "      <td>0.904533</td>\n",
       "      <td>-0.717924</td>\n",
       "      <td>1.226208</td>\n",
       "      <td>-0.198730</td>\n",
       "      <td>-0.261541</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.300872</td>\n",
       "      <td>-0.735995</td>\n",
       "      <td>0.186777</td>\n",
       "      <td>0.588969</td>\n",
       "      <td>-0.354524</td>\n",
       "      <td>0.107859</td>\n",
       "      <td>0.214559</td>\n",
       "      <td>0.090296</td>\n",
       "      <td>49.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Time        V1        V2        V3        V4        V5        V6  \\\n",
       "0  131418.0 -1.418343  2.074760 -1.683303 -1.708984  1.340667 -0.802904   \n",
       "1   30575.0 -2.007359 -1.812544  2.467946  0.717333  0.860664 -0.474420   \n",
       "2   48759.0 -1.455090  1.745371  0.393814  0.370542  0.419204  0.547102   \n",
       "3   66544.0  1.124034 -0.343542  1.361168  0.387759 -1.390420 -0.663302   \n",
       "4  121099.0  0.072966  1.004738 -0.452590 -0.530909  0.904533 -0.717924   \n",
       "\n",
       "         V7        V8        V9  ...       V21       V22       V23       V24  \\\n",
       "0  1.571283 -0.183383  0.610996  ... -0.016737  0.831867 -0.287168  0.217734   \n",
       "1 -1.195674  0.418655 -1.559050  ...  0.122850  0.295340  0.275766  0.213621   \n",
       "2 -0.058742 -0.476353 -0.677755  ...  0.920543 -0.148314 -0.188817 -1.033784   \n",
       "3 -0.530391 -0.051080  0.999240  ... -0.170236 -0.236974  0.109470  1.023537   \n",
       "4  1.226208 -0.198730 -0.261541  ... -0.300872 -0.735995  0.186777  0.588969   \n",
       "\n",
       "        V25       V26       V27       V28  Amount  Class  \n",
       "0 -0.062399 -0.017927  0.005060 -0.455670    3.70      0  \n",
       "1  0.368420 -0.093973  0.056136  0.122159   97.00      0  \n",
       "2 -0.091466 -0.409897 -0.612491  0.083665    5.00      0  \n",
       "3  0.092587  0.903247 -0.030670  0.026613   34.66      0  \n",
       "4 -0.354524  0.107859  0.214559  0.090296   49.99      0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os \n",
    "\n",
    "data_path = os.path.join('./dataset', 'creditcard.csv')\n",
    "df = pd.read_csv(data_path, low_memory=False)\n",
    "df = df.sample(frac=1).reset_index(drop=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have 492 fraud data points and 284315 nonfraudulent data points.\n"
     ]
    }
   ],
   "source": [
    "frauds = df.loc[df['Class'] == 1]\n",
    "non_frauds = df.loc[df['Class'] == 0]\n",
    "print(\"We have\", len(frauds), \"fraud data points and\", len(non_frauds), \"nonfraudulent data points.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X and y sizes, respectively: (284807, 30) (284807,)\n",
      "Train and test sizes, respectively: 185124 185124 | 99683 99683\n",
      "Total number of frauds: 492 -- 0.001727485630620034\n",
      "Number of frauds on y_test: 166 -- 0.0016652789342214821\n",
      "Number of frauds on y_train: 326 -- 0.0017609818283961022\n"
     ]
    }
   ],
   "source": [
    "from sklearn import datasets, linear_model\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = df.iloc[:,:-1]\n",
    "y = df['Class']\n",
    "\n",
    "print(\"X and y sizes, respectively:\", X.shape, y.shape)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.35)\n",
    "print(\"Train and test sizes, respectively:\", len(X_train), len(y_train), \"|\", len(X_test), len(y_test))\n",
    "print(\"Total number of frauds:\", len(y.loc[df['Class'] == 1]), '--', len(y.loc[df['Class'] == 1])/len(y))\n",
    "print(\"Number of frauds on y_test:\", len(y_test.loc[df['Class'] == 1]), '--',len(y_test.loc[df['Class'] == 1]) / len(y_test))\n",
    "print(\"Number of frauds on y_train:\", len(y_train.loc[df['Class'] == 1]), '--', len(y_train.loc[df['Class'] == 1])/len(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.009389\n",
      "         Iterations 13\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                  Class   No. Observations:               185124\n",
      "Model:                          Logit   Df Residuals:                   185094\n",
      "Method:                           MLE   Df Model:                           29\n",
      "Date:                Sat, 28 Nov 2020   Pseudo R-squ.:                  0.2737\n",
      "Time:                        21:45:23   Log-Likelihood:                -1738.2\n",
      "converged:                       True   LL-Null:                       -2393.2\n",
      "Covariance Type:            nonrobust   LLR p-value:                1.670e-257\n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "Time       -8.811e-05   2.02e-06    -43.662      0.000   -9.21e-05   -8.42e-05\n",
      "V1             0.5741      0.044     13.016      0.000       0.488       0.661\n",
      "V2            -1.4770      0.052    -28.323      0.000      -1.579      -1.375\n",
      "V3            -1.6288      0.044    -36.975      0.000      -1.715      -1.542\n",
      "V4             0.3944      0.039     10.059      0.000       0.318       0.471\n",
      "V5            -1.0493      0.077    -13.702      0.000      -1.199      -0.899\n",
      "V6             0.5386      0.057      9.480      0.000       0.427       0.650\n",
      "V7             1.6347      0.084     19.570      0.000       1.471       1.798\n",
      "V8            -0.5065      0.030    -16.739      0.000      -0.566      -0.447\n",
      "V9            -0.7982      0.070    -11.385      0.000      -0.936      -0.661\n",
      "V10           -0.9537      0.084    -11.330      0.000      -1.119      -0.789\n",
      "V11           -0.5617      0.053    -10.619      0.000      -0.665      -0.458\n",
      "V12           -0.0134      0.055     -0.243      0.808      -0.121       0.095\n",
      "V13           -0.3958      0.053     -7.460      0.000      -0.500      -0.292\n",
      "V14           -0.5194      0.050    -10.491      0.000      -0.616      -0.422\n",
      "V15           -0.9806      0.062    -15.915      0.000      -1.101      -0.860\n",
      "V16           -0.5162      0.067     -7.739      0.000      -0.647      -0.385\n",
      "V17           -0.5852      0.052    -11.299      0.000      -0.687      -0.484\n",
      "V18            0.4965      0.073      6.759      0.000       0.353       0.641\n",
      "V19           -0.3595      0.076     -4.744      0.000      -0.508      -0.211\n",
      "V20            2.6426      0.213     12.410      0.000       2.225       3.060\n",
      "V21            1.5260      0.086     17.813      0.000       1.358       1.694\n",
      "V22            0.7758      0.104      7.433      0.000       0.571       0.980\n",
      "V23            0.5437      0.155      3.505      0.000       0.240       0.848\n",
      "V24           -0.0493      0.087     -0.566      0.571      -0.220       0.121\n",
      "V25           -1.6416      0.117    -14.075      0.000      -1.870      -1.413\n",
      "V26            0.2773      0.110      2.524      0.012       0.062       0.493\n",
      "V27           -1.5621      0.169     -9.242      0.000      -1.893      -1.231\n",
      "V28            0.5984      0.143      4.180      0.000       0.318       0.879\n",
      "Amount        -0.0243      0.001    -21.699      0.000      -0.027      -0.022\n",
      "==============================================================================\n",
      "\n",
      "Possibly complete quasi-separation: A fraction 0.59 of observations can be\n",
      "perfectly predicted. This might indicate that there is complete\n",
      "quasi-separation. In this case some parameters will not be identified.\n"
     ]
    }
   ],
   "source": [
    "import statsmodels.api as sm\n",
    "\n",
    "logit_model = sm.Logit(y_train,X_train)\n",
    "result = logit_model.fit()\n",
    "print(result.summary())\n",
    "\n",
    "# y_predicted = np.array(logistic.predict(X_test))\n",
    "# y_right = np.array(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can drop `V12` `V24` for simplicity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V19</th>\n",
       "      <th>V20</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>880</th>\n",
       "      <td>158712.0</td>\n",
       "      <td>-0.809194</td>\n",
       "      <td>0.115803</td>\n",
       "      <td>-2.129629</td>\n",
       "      <td>-1.652926</td>\n",
       "      <td>0.202177</td>\n",
       "      <td>-0.986389</td>\n",
       "      <td>2.697194</td>\n",
       "      <td>-0.251622</td>\n",
       "      <td>-0.696479</td>\n",
       "      <td>...</td>\n",
       "      <td>0.405771</td>\n",
       "      <td>0.528314</td>\n",
       "      <td>0.623771</td>\n",
       "      <td>1.164183</td>\n",
       "      <td>0.469044</td>\n",
       "      <td>0.168189</td>\n",
       "      <td>0.903844</td>\n",
       "      <td>-0.181694</td>\n",
       "      <td>0.133513</td>\n",
       "      <td>359.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21808</th>\n",
       "      <td>45001.0</td>\n",
       "      <td>-0.497740</td>\n",
       "      <td>1.682160</td>\n",
       "      <td>-0.883561</td>\n",
       "      <td>0.500387</td>\n",
       "      <td>1.003282</td>\n",
       "      <td>1.563936</td>\n",
       "      <td>-2.134137</td>\n",
       "      <td>-5.079111</td>\n",
       "      <td>-1.373160</td>\n",
       "      <td>...</td>\n",
       "      <td>0.836383</td>\n",
       "      <td>1.427697</td>\n",
       "      <td>-2.685652</td>\n",
       "      <td>0.313659</td>\n",
       "      <td>-0.406392</td>\n",
       "      <td>0.995879</td>\n",
       "      <td>0.681009</td>\n",
       "      <td>0.019808</td>\n",
       "      <td>0.251145</td>\n",
       "      <td>0.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29650</th>\n",
       "      <td>72858.0</td>\n",
       "      <td>0.307455</td>\n",
       "      <td>-1.089231</td>\n",
       "      <td>-0.080013</td>\n",
       "      <td>2.884927</td>\n",
       "      <td>-0.364474</td>\n",
       "      <td>0.385788</td>\n",
       "      <td>0.634557</td>\n",
       "      <td>-0.089326</td>\n",
       "      <td>-0.286705</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.417156</td>\n",
       "      <td>0.793361</td>\n",
       "      <td>0.003825</td>\n",
       "      <td>-0.954862</td>\n",
       "      <td>-0.494171</td>\n",
       "      <td>0.417813</td>\n",
       "      <td>-0.088909</td>\n",
       "      <td>-0.091142</td>\n",
       "      <td>0.095542</td>\n",
       "      <td>478.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87735</th>\n",
       "      <td>93930.0</td>\n",
       "      <td>-0.448284</td>\n",
       "      <td>0.684104</td>\n",
       "      <td>0.128183</td>\n",
       "      <td>-0.614104</td>\n",
       "      <td>0.843270</td>\n",
       "      <td>-1.193620</td>\n",
       "      <td>1.547435</td>\n",
       "      <td>-0.718151</td>\n",
       "      <td>-1.354251</td>\n",
       "      <td>...</td>\n",
       "      <td>0.179386</td>\n",
       "      <td>-0.151744</td>\n",
       "      <td>-0.181042</td>\n",
       "      <td>0.231762</td>\n",
       "      <td>-0.538865</td>\n",
       "      <td>1.189820</td>\n",
       "      <td>1.282062</td>\n",
       "      <td>-0.101881</td>\n",
       "      <td>0.022023</td>\n",
       "      <td>64.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74927</th>\n",
       "      <td>61698.0</td>\n",
       "      <td>0.260654</td>\n",
       "      <td>-2.557308</td>\n",
       "      <td>0.597547</td>\n",
       "      <td>-0.152963</td>\n",
       "      <td>-1.712075</td>\n",
       "      <td>1.090696</td>\n",
       "      <td>-0.755417</td>\n",
       "      <td>0.374810</td>\n",
       "      <td>-0.118935</td>\n",
       "      <td>...</td>\n",
       "      <td>0.325470</td>\n",
       "      <td>0.965348</td>\n",
       "      <td>0.402483</td>\n",
       "      <td>0.230155</td>\n",
       "      <td>-0.373145</td>\n",
       "      <td>0.008700</td>\n",
       "      <td>-0.253050</td>\n",
       "      <td>-0.012552</td>\n",
       "      <td>0.092829</td>\n",
       "      <td>501.43</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Time        V1        V2        V3        V4        V5        V6  \\\n",
       "880    158712.0 -0.809194  0.115803 -2.129629 -1.652926  0.202177 -0.986389   \n",
       "21808   45001.0 -0.497740  1.682160 -0.883561  0.500387  1.003282  1.563936   \n",
       "29650   72858.0  0.307455 -1.089231 -0.080013  2.884927 -0.364474  0.385788   \n",
       "87735   93930.0 -0.448284  0.684104  0.128183 -0.614104  0.843270 -1.193620   \n",
       "74927   61698.0  0.260654 -2.557308  0.597547 -0.152963 -1.712075  1.090696   \n",
       "\n",
       "             V7        V8        V9  ...       V19       V20       V21  \\\n",
       "880    2.697194 -0.251622 -0.696479  ...  0.405771  0.528314  0.623771   \n",
       "21808 -2.134137 -5.079111 -1.373160  ...  0.836383  1.427697 -2.685652   \n",
       "29650  0.634557 -0.089326 -0.286705  ... -0.417156  0.793361  0.003825   \n",
       "87735  1.547435 -0.718151 -1.354251  ...  0.179386 -0.151744 -0.181042   \n",
       "74927 -0.755417  0.374810 -0.118935  ...  0.325470  0.965348  0.402483   \n",
       "\n",
       "            V22       V23       V25       V26       V27       V28  Amount  \n",
       "880    1.164183  0.469044  0.168189  0.903844 -0.181694  0.133513  359.83  \n",
       "21808  0.313659 -0.406392  0.995879  0.681009  0.019808  0.251145    0.76  \n",
       "29650 -0.954862 -0.494171  0.417813 -0.088909 -0.091142  0.095542  478.35  \n",
       "87735  0.231762 -0.538865  1.189820  1.282062 -0.101881  0.022023   64.99  \n",
       "74927  0.230155 -0.373145  0.008700 -0.253050 -0.012552  0.092829  501.43  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = X_train.drop(['V12', 'V24'], axis=1)\n",
    "X_test = X_test.drop(['V12', 'V24'], axis=1)\n",
    "\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression \n",
    " \n",
    "log_clf = LogisticRegression(max_iter=500)\n",
    "log_clf.fit(X_train, y_train)\n",
    " \n",
    "y_predict = log_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix:\n",
      "[[99497    20]\n",
      " [   70    96]]\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     99517\n",
      "           1       0.83      0.58      0.68       166\n",
      "\n",
      "    accuracy                           1.00     99683\n",
      "   macro avg       0.91      0.79      0.84     99683\n",
      "weighted avg       1.00      1.00      1.00     99683\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, '2-class Precision-Recall curve: AUC=0.48')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "\n",
    "confusion = confusion_matrix(y_test, y_predict)\n",
    "print(\"Confusion matrix:\\n%s\" % confusion)\n",
    "print('\\n')\n",
    "print(classification_report(y_test, y_predict))\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
